{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load some data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "\n",
    "dataset = load_boston()\n",
    "X = dataset.data\n",
    "y = (dataset.target > 21).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train a very simple XGB model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:11:42] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=4, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "# NOTE: The model must implement `predict`, `predict_proba`, and `get_booster` methods.\n",
    "model = XGBClassifier()\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       249\n",
      "           1       1.00      1.00      1.00       257\n",
      "\n",
      "    accuracy                           1.00       506\n",
      "   macro avg       1.00      1.00      1.00       506\n",
      "weighted avg       1.00      1.00      1.00       506\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y, model.predict(X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explanations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following example shows how to use the package to generate the feature importance explanations with 100-NN as counterfactual generator and the SHAP TreeExplainer as feature importance estimator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's setup the explainers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cfshap.utils.preprocessing import EfficientQuantileTransformer\n",
    "from cfshap.counterfactuals import KNNCounterfactuals\n",
    "from cfshap.attribution import TreeExplainer, CompositeExplainer\n",
    "from cfshap.trend import TrendEstimator\n",
    "\n",
    "MAX_SAMPLES = 10000\n",
    "\n",
    "# We will need a scaler in the input space for the counterfactual generator\n",
    "scaler = EfficientQuantileTransformer()\n",
    "scaler.fit(X)\n",
    "\n",
    "# Background/Counterfactuals generator\n",
    "background_generator = KNNCounterfactuals(\n",
    "    model=model,\n",
    "    X=X,\n",
    "    n_neighbors=100,\n",
    "    distance='cityblock',\n",
    "    scaler=scaler,\n",
    "    max_samples=MAX_SAMPLES,\n",
    ")\n",
    "\n",
    "# We will need a trend estimator for the attribution estimator\n",
    "trend_estimator = TrendEstimator(strategy='mean')\n",
    "\n",
    "# Feature importance estimator\n",
    "importance_estimator = TreeExplainer(\n",
    "    model,\n",
    "    data=None,\n",
    "    trend_estimator=trend_estimator,\n",
    "    max_samples=MAX_SAMPLES,\n",
    ")\n",
    "\n",
    "# Let's setup the explainer\n",
    "explainer = CompositeExplainer(\n",
    "    background_generator,\n",
    "    importance_estimator,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compute the explanations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's generate the explanations for the first 10 samples\n",
    "explanations = explainer(X[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the feature importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.368411</td>\n",
       "      <td>0.001084</td>\n",
       "      <td>0.016953</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>-0.071173</td>\n",
       "      <td>4.944348</td>\n",
       "      <td>0.451436</td>\n",
       "      <td>0.599951</td>\n",
       "      <td>-0.124420</td>\n",
       "      <td>0.468224</td>\n",
       "      <td>2.566800</td>\n",
       "      <td>0.262139</td>\n",
       "      <td>4.089339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.688685</td>\n",
       "      <td>0.025537</td>\n",
       "      <td>0.117732</td>\n",
       "      <td>-0.005397</td>\n",
       "      <td>0.482204</td>\n",
       "      <td>4.693255</td>\n",
       "      <td>-0.375660</td>\n",
       "      <td>0.659881</td>\n",
       "      <td>-0.073497</td>\n",
       "      <td>0.737982</td>\n",
       "      <td>2.195861</td>\n",
       "      <td>0.174194</td>\n",
       "      <td>1.450351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.620587</td>\n",
       "      <td>0.052311</td>\n",
       "      <td>0.077167</td>\n",
       "      <td>-0.000131</td>\n",
       "      <td>0.274878</td>\n",
       "      <td>5.873381</td>\n",
       "      <td>0.460579</td>\n",
       "      <td>0.618844</td>\n",
       "      <td>-0.067338</td>\n",
       "      <td>0.596424</td>\n",
       "      <td>1.719293</td>\n",
       "      <td>1.094380</td>\n",
       "      <td>3.774376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.564064</td>\n",
       "      <td>0.052311</td>\n",
       "      <td>-0.024788</td>\n",
       "      <td>-0.000697</td>\n",
       "      <td>-0.027789</td>\n",
       "      <td>6.080283</td>\n",
       "      <td>1.029735</td>\n",
       "      <td>0.026832</td>\n",
       "      <td>-0.094110</td>\n",
       "      <td>0.537722</td>\n",
       "      <td>0.824205</td>\n",
       "      <td>0.410816</td>\n",
       "      <td>4.969478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.184132</td>\n",
       "      <td>0.040598</td>\n",
       "      <td>-0.017089</td>\n",
       "      <td>-0.000951</td>\n",
       "      <td>-0.041633</td>\n",
       "      <td>6.125439</td>\n",
       "      <td>1.021442</td>\n",
       "      <td>-0.010025</td>\n",
       "      <td>-0.098910</td>\n",
       "      <td>0.545943</td>\n",
       "      <td>0.753446</td>\n",
       "      <td>0.025192</td>\n",
       "      <td>5.016416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.679237</td>\n",
       "      <td>0.055874</td>\n",
       "      <td>-0.008300</td>\n",
       "      <td>-0.004868</td>\n",
       "      <td>0.023068</td>\n",
       "      <td>4.939248</td>\n",
       "      <td>0.722469</td>\n",
       "      <td>0.146560</td>\n",
       "      <td>-0.073102</td>\n",
       "      <td>0.533288</td>\n",
       "      <td>0.847074</td>\n",
       "      <td>0.365709</td>\n",
       "      <td>5.043894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.520886</td>\n",
       "      <td>0.033432</td>\n",
       "      <td>0.165588</td>\n",
       "      <td>-0.004216</td>\n",
       "      <td>0.376512</td>\n",
       "      <td>0.846783</td>\n",
       "      <td>1.195629</td>\n",
       "      <td>0.915779</td>\n",
       "      <td>0.055242</td>\n",
       "      <td>0.292543</td>\n",
       "      <td>3.424313</td>\n",
       "      <td>0.603873</td>\n",
       "      <td>0.481862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.987279</td>\n",
       "      <td>0.015798</td>\n",
       "      <td>0.337859</td>\n",
       "      <td>-0.016991</td>\n",
       "      <td>0.358317</td>\n",
       "      <td>2.485108</td>\n",
       "      <td>-0.892284</td>\n",
       "      <td>0.692895</td>\n",
       "      <td>-0.002049</td>\n",
       "      <td>0.214700</td>\n",
       "      <td>3.336585</td>\n",
       "      <td>0.318524</td>\n",
       "      <td>0.272250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.301995</td>\n",
       "      <td>0.057322</td>\n",
       "      <td>-0.046974</td>\n",
       "      <td>-0.038744</td>\n",
       "      <td>-0.163927</td>\n",
       "      <td>-3.900997</td>\n",
       "      <td>-2.276446</td>\n",
       "      <td>-2.736532</td>\n",
       "      <td>-0.115068</td>\n",
       "      <td>-0.372046</td>\n",
       "      <td>0.581672</td>\n",
       "      <td>-0.156959</td>\n",
       "      <td>-3.378510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.220481</td>\n",
       "      <td>0.065478</td>\n",
       "      <td>0.046834</td>\n",
       "      <td>-0.066511</td>\n",
       "      <td>-0.208922</td>\n",
       "      <td>-2.391635</td>\n",
       "      <td>-2.432828</td>\n",
       "      <td>-3.073034</td>\n",
       "      <td>-0.103017</td>\n",
       "      <td>-0.273681</td>\n",
       "      <td>0.769095</td>\n",
       "      <td>-0.363471</td>\n",
       "      <td>-2.573689</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       CRIM        ZN     INDUS      CHAS       NOX        RM       AGE  \\\n",
       "0 -0.368411  0.001084  0.016953  0.000066 -0.071173  4.944348  0.451436   \n",
       "1 -0.688685  0.025537  0.117732 -0.005397  0.482204  4.693255 -0.375660   \n",
       "2 -0.620587  0.052311  0.077167 -0.000131  0.274878  5.873381  0.460579   \n",
       "3 -0.564064  0.052311 -0.024788 -0.000697 -0.027789  6.080283  1.029735   \n",
       "4  0.184132  0.040598 -0.017089 -0.000951 -0.041633  6.125439  1.021442   \n",
       "5 -0.679237  0.055874 -0.008300 -0.004868  0.023068  4.939248  0.722469   \n",
       "6  0.520886  0.033432  0.165588 -0.004216  0.376512  0.846783  1.195629   \n",
       "7  0.987279  0.015798  0.337859 -0.016991  0.358317  2.485108 -0.892284   \n",
       "8 -0.301995  0.057322 -0.046974 -0.038744 -0.163927 -3.900997 -2.276446   \n",
       "9  0.220481  0.065478  0.046834 -0.066511 -0.208922 -2.391635 -2.432828   \n",
       "\n",
       "        DIS       RAD       TAX   PTRATIO         B     LSTAT  \n",
       "0  0.599951 -0.124420  0.468224  2.566800  0.262139  4.089339  \n",
       "1  0.659881 -0.073497  0.737982  2.195861  0.174194  1.450351  \n",
       "2  0.618844 -0.067338  0.596424  1.719293  1.094380  3.774376  \n",
       "3  0.026832 -0.094110  0.537722  0.824205  0.410816  4.969478  \n",
       "4 -0.010025 -0.098910  0.545943  0.753446  0.025192  5.016416  \n",
       "5  0.146560 -0.073102  0.533288  0.847074  0.365709  5.043894  \n",
       "6  0.915779  0.055242  0.292543  3.424313  0.603873  0.481862  \n",
       "7  0.692895 -0.002049  0.214700  3.336585  0.318524  0.272250  \n",
       "8 -2.736532 -0.115068 -0.372046  0.581672 -0.156959 -3.378510  \n",
       "9 -3.073034 -0.103017 -0.273681  0.769095 -0.363471 -2.573689  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(explanations.values, columns = dataset.feature_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.13 ('cfshap22')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5d73c2996b259ea22e5d0650a896d0efbecd5947915724f210632909fcf81dcb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
